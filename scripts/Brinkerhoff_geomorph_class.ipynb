{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1> <font color=steelblue>Constraining River Discharge Estimation Priors Using Reach-Scale Geomorphology</font></h1>\n",
    "<br>\n",
    "    Craig Brinkerhoff <br>\n",
    "    Colin Gleason <br>\n",
    "    Peirong Lin <br>\n",
    "    Konstantinos Andreadis <br>\n",
    "    Mark Hagemann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><font color=darkcyan> What? </font></h3>\n",
    "<p>\n",
    "BAM uses Bayesian inference to estimate river discharge and thus relies on prior distributions of certain variables. Also to be devolped for SADS and MetroMan\n",
    "</p> <br>\n",
    "<h5>\n",
    "    So, can we produce better discharge estimates by constraining these priors by river type?\n",
    "    <br><br>\n",
    "    AND, how does our classification of American river geomorphology vary as a direct function of the hydrographic network used? i.e. are results fundamentally different if using coarser hydrographic networks, wherein many smaller rivers are functionally non-existent?\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><font color=darkcyan> MERIT Hydro </font></h3>\n",
    "\n",
    "<p> This work is performed on a dataset of USGS field mesurements of channel hydraulics originally collected by Barber and Gleason (2018) joined to NHD, resulting in an expanded version of the dataset used in Brinkerhoff, et al. (2019)\n",
    "    <br><br>\n",
    "    Stream Order <br>\n",
    "    Slope <br>\n",
    "    Stream Drop <br>\n",
    "    Maximum Grain Size Entrained (Henderson, 1966) <br>\n",
    "    Shear Stress <br>\n",
    "    Froude Number <br>\n",
    "    Drainage Area <br>\n",
    "    Unit Stream Power <br>\n",
    "    Channel Shape <br>\n",
    "    Channel Width <br>\n",
    "    Channel Depth <br>\n",
    "    Channel Velocity <br>\n",
    "    Sinuosity <br>\n",
    "    Bankfull Shape <br>\n",
    "    Bankfull Width <br>\n",
    "    Bankfull Depth <br>\n",
    "    Bankfull Velocity <br>\n",
    "    # rivers draining into reach ('topology')<br>\n",
    "    <br><br>It must be stressed that these joined variables exist at the reach-scale, while the field measurements exist at the cross-section scale. Also, these results are only reflective of the hydrology/geomorphology of river reaches measured by the USGS, generally at streamagauges. IMPORTANT.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3><font color=darkcyan> USGS NHD 2.1 </font></h3>\n",
    "\n",
    "<p> This work is performed on a dataset of USGS field mesurements of channel hydraulics originally collected by Barber and Gleason (2018) joined to NHD, resulting in an expanded version of the dataset used in Brinkerhoff, et al. (2019, in review)\n",
    "    <br><br>\n",
    "    Stream Order <br>\n",
    "    Slope <br>\n",
    "    Distance Downstream <br>\n",
    "    Maximum Grain Size Entrained (Henderson, 1966) <br>\n",
    "    Shear Stress <br>\n",
    "    Froude Number <br>\n",
    "    Drainage Area <br>\n",
    "    Unit Stream Power <br>\n",
    "    Channel Shape <br>\n",
    "    Channel Width <br>\n",
    "    Channel Depth <br>\n",
    "    Channel Velocity <br>\n",
    "    Bankfull Shape <br>\n",
    "    Bankfull Width <br>\n",
    "    Bankfull Depth <br>\n",
    "    Bankfull Velocity <br>\n",
    "    Reach Type (i.e. perennial, intermittent, lake/wetland/reservoir, canal, or connector).<br>\n",
    "    Sinuosity (eventually)\n",
    "    <br><br>It must be stressed that these joined variables exist at the reach-scale, while the field measurements exist at the cross-section scale. Also, these results are only reflective of the hydrology/geomorphology of river reaches measured by the USGS, generally at streamagauges. IMPORTANT.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3><font color=darkcyan> Necessary preprocessing on NHD </font></h3>\n",
    "<p> NHD for some reason has assigned many main stem or close-to-main stem reaches as artifical paths and not rivers.  Artifical paths are only supposed to be for throughflow lines in lakes/wetlands/reservoirs.\n",
    "<br><br>\n",
    "So, I identified reaches classed as 'ArtificalPath' that had no corresponding waterbodyID in the lakes dataset, assumed main stem reaches are perrenial, and reclassified those reaches as perrenial rivers.\n",
    "<br><br> Canals and NHD's 'connectors' are listed as Artifical Channels.  'Connectors' are reaches the NHD had to add to make the network continuous in some places (i.e. trhough dams)\n",
    "<br><br>\n",
    "I am using the NHD's defintion of river intermittncy.  It's unclear how they designate perrenial/intermittent/ephemeral (no ephemeral reaches had measurements on them)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen> Initial Data Preperation, Wrangling, and Cleaning </font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats.mstats as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import linear_model\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.tile_providers import CARTODBPOSITRON\n",
    "from ast import literal_eval\n",
    "\n",
    "#set working directory here\n",
    "os.chdir(\"C:\\\\Users\\\\craig\\\\Box Sync\\\\Ongoing Projects\\\\geomorph_class\\\\\")\n",
    "\n",
    "#load in barber dataset\n",
    "Hydroshortened = pd.read_csv('Barber_rivers.csv', low_memory=False, encoding='latin-1')\n",
    "\n",
    "#MERIT Hydro\n",
    "#MERITshortened = pd.read_table('MERIT_Hydro_reaches2.txt', sep=',') #all reaches and atributes\n",
    "#MERITshortened['COMID'] = MERITshortened['COMID'].astype('int32')\n",
    "#MERITshortened = MERITshortened[MERITshortened['stationid'].str.startswith('USGS')]\n",
    "#MERITshortened['stationid'] = MERITshortened['stationid'].str[5:]\n",
    "#MERITshortened['stationid'] = pd.to_numeric(MERITshortened['stationid'])\n",
    "\n",
    "#MERITshortened = pd.merge(MERITshortened, Hydroshortened, left_on='stationid', right_on='site_no') #merge on usgs gauge ID\n",
    "\n",
    "#NHD 2.1 flowlines (with USGS gauges on them) and lakes\n",
    "med_NHD = pd.read_csv('C:\\\\Users\\\\craig\\\\Box Sync\\\\Published\\\\hydraulic_geometry_project_2019\\\\working\\\\NHD_med_res.csv', low_memory=False, encoding='latin-1')\n",
    "med_NHD_lakes = pd.read_csv('med_NHD_lakes.csv', low_memory=False, encoding='latin-1')\n",
    "\n",
    "#NHD sinuosity from  Wieczorek, M.E., Jackson, S.E., and Schwarz, G.E., 2018, Select Attributes for NHDPlus Version 2.1 Reach Catchments and Modified Network Routed Upstream Watersheds for the Conterminous United States: U.S. Geological Survey data release, https://doi.org/10.5066/F7765D7V. \n",
    "sinuosityCONUS = pd.read_csv('Sinuousity_CONUS.txt', delimiter=',')\n",
    "\n",
    "Hydroshortened = pd.merge(Hydroshortened, med_NHD[['SOURCE_FEA', 'COMID', 'SLOPE', 'StreamOrde', 'ArbolateSu', 'Measure', 'LENGTHKM', 'LatSite', 'LonSite', 'FTYPE', 'FCODE', 'DASqKm', 'Tidal', 'WBAREACOMI', 'TOTMA']],left_on='site_no', right_on='SOURCE_FEA')\n",
    "Hydroshortened = pd.merge(Hydroshortened, sinuosityCONUS, left_on='COMID', right_on='COMID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=darkcyan> Analysis Using USGS NHD 2.1 </font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h4><font color=darkolivegreen>Calculate mean hydraulic depth, fix channel material names, and some cleaning</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Hydroshortened['chan_depth'] = Hydroshortened['chan_area']/Hydroshortened['chan_width']\n",
    "Hydroshortened['chan_material'] = np.where(Hydroshortened['chan_material'] == 'silt', 'SILT', Hydroshortened['chan_material'])\n",
    "\n",
    "#some cleaning (NA values and hydraulics below 0)\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_width'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_depth'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_discharge'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['measured_rating_diff'] != 'Poor']\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['measured_rating_diff'] != 'POOR']\n",
    "\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_width'].notnull()]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_depth'].notnull()]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_discharge'].notnull()]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_width'].notna()]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_depth'].notna()]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['chan_discharge'].notna()]\n",
    "\n",
    "#convert needed units to metric\n",
    "Hydroshortened['chan_width'] = Hydroshortened['chan_width']*0.305\n",
    "Hydroshortened['chan_depth'] = Hydroshortened['chan_depth']*0.305\n",
    "#Hydroshortened['bank_width'] = Hydroshortened['bank_width']*0.305\n",
    "#Hydroshortened['bank_depth'] = Hydroshortened['bank_depth']*0.305\n",
    "Hydroshortened['chan_velocity'] = Hydroshortened['chan_velocity']*0.305\n",
    "Hydroshortened['chan_discharge'] = Hydroshortened['chan_discharge']*0.028\n",
    "#Hydroshortened['bank_Q'] = Hydroshortened['bank_Q']*0.028"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><font color=darkolivegreen>Calculate more variables and AHG</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Hydroshortened['n'] = ((Hydroshortened['chan_depth'])**(2/3)*Hydroshortened['SLOPE']**(1/2))/Hydroshortened['chan_velocity']\n",
    "Hydroshortened['shearStress'] = 9.81*Hydroshortened['chan_depth']*Hydroshortened['SLOPE']\n",
    "Hydroshortened['Fb'] = Hydroshortened['chan_velocity']/((Hydroshortened['chan_depth']*9.81)**(1/2))\n",
    "Hydroshortened['minEntrain'] = 11*Hydroshortened['chan_depth']*Hydroshortened['SLOPE']\n",
    "\n",
    "#A0\n",
    "Hydroshortened = Hydroshortened.join(Hydroshortened.groupby('site_no')['chan_area'].agg(['median']), on='site_no')\n",
    "Hydroshortened = Hydroshortened.rename(columns={\"median\": \"A0\"})\n",
    "\n",
    "#AHG exp function\n",
    "def regress(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params[0] #only get exp\n",
    "\n",
    "#AHG int function\n",
    "def regress2(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params[1] #only get int\n",
    "\n",
    "\n",
    "groupSize = Hydroshortened.groupby('site_no').size().to_frame()\n",
    "Hydroshortened = Hydroshortened.merge(groupSize, on='site_no')\n",
    "\n",
    "b_temp = Hydroshortened.groupby('site_no').apply(regress, 'chan_width', ['chan_discharge']).to_frame()\n",
    "a_temp = Hydroshortened.groupby('site_no').apply(regress2, 'chan_width', ['chan_discharge']).to_frame()\n",
    "f_temp = Hydroshortened.groupby('site_no').apply(regress, 'chan_depth', ['chan_discharge']).to_frame()\n",
    "c_temp = Hydroshortened.groupby('site_no').apply(regress2, 'chan_depth', ['chan_discharge']).to_frame()\n",
    "m_temp = Hydroshortened.groupby('site_no').apply(regress, 'chan_velocity', ['chan_discharge']).to_frame()\n",
    "k_temp = Hydroshortened.groupby('site_no').apply(regress2, 'chan_velocity', ['chan_discharge']).to_frame()\n",
    "\n",
    "Hydroshortened =  pd.merge(Hydroshortened, b_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, a_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_y': \"b\"})\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_x': \"AHGsize\"})\n",
    "Hydroshortened = Hydroshortened.rename(columns={0: \"loga\"})\n",
    "\n",
    "Hydroshortened =  pd.merge(Hydroshortened, f_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, m_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_y': \"m\"})\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_x': \"f\"})\n",
    "\n",
    "Hydroshortened =  pd.merge(Hydroshortened, c_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, k_temp, right_index=True, left_on='site_no')\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_y': \"logc\"})\n",
    "Hydroshortened = Hydroshortened.rename(columns={'0_x': \"logk\"})\n",
    "\n",
    "Hydroshortened['r'] = Hydroshortened['f']/Hydroshortened['b']\n",
    "Hydroshortened['unitPower'] = (998*9.8*Hydroshortened['chan_discharge']*Hydroshortened['SLOPE'])/Hydroshortened['chan_width']\n",
    "Hydroshortened['DistDwnstrm'] = Hydroshortened['ArbolateSu']-((Hydroshortened['Measure']/100)*Hydroshortened['LENGTHKM'])\n",
    "Hydroshortened['chan_material_index'] = np.where(Hydroshortened['chan_material'] == 'BLDR', 1,\n",
    "                                                np.where(Hydroshortened['chan_material'] == 'GRVL', 2,\n",
    "                                                        np.where(Hydroshortened['chan_material'] == 'SAND', 3,\n",
    "                                                                np.where(Hydroshortened['chan_material'] == 'SILT', 4,\n",
    "                                                                        np.where(Hydroshortened['chan_material'] == 'UNSP', 5,5)))))\n",
    "\n",
    "Hydroshortened['FCODEnorm'] = np.where(Hydroshortened['FCODE'] == 33400, 1, #connectors or canals\n",
    "                                                np.where(Hydroshortened['FCODE'] == 33600, 1, #connectors or canal\n",
    "                                                        np.where(Hydroshortened['FCODE'] == 46003, 2, #intermittent river\n",
    "                                                                np.where(Hydroshortened['FCODE'] == 46006, 3, #perienial river\n",
    "                                                                        np.where(Hydroshortened['WBAREACOMI'].isin(med_NHD_lakes['COMID']), 4,3))))) #lake if also in lakes dataset, otherwise its a main stem river or tidal reach and can be reclassified as perrenial river (basically....)\n",
    "\n",
    "Hydroshortened['FTYPE'] = np.where(Hydroshortened['FCODE'] == 33400, 'ArtificalChannel', #connector or canal\n",
    "                                                np.where(Hydroshortened['FCODE'] == 33600, 'ArtificalChannel', #connector or canal\n",
    "                                                        np.where(Hydroshortened['FCODE'] == 46003, 'IntermittentRiver', #intermittent river\n",
    "                                                                np.where(Hydroshortened['FCODE'] == 46006, 'PerennialRiver', #perienial river\n",
    "                                                                        np.where(Hydroshortened['WBAREACOMI'].isin(med_NHD_lakes['COMID']), 'Lake/Reservoir/Wetland','PerennialRiver')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bankfull hydraulics function\n",
    "def calculate_bankful(df, colname, retPeriod):\n",
    "    # sort data smallest to largest\n",
    "    sorted_data = df.sort_values(by=colname, ascending = False)\n",
    "    # count total obervations\n",
    "    n = sorted_data.shape[0]\n",
    "    # add a numbered column 1 -> n to use in return calculation for rank\n",
    "    sorted_data.insert(0, 'rank', range(1, 1 + n))\n",
    "    #find desired rank\n",
    "    desiredRank = (n+1)/retPeriod\n",
    "    desiredRank = round(desiredRank)\n",
    "    \n",
    "    #get variable with desired rank\n",
    "    output = sorted_data.loc[sorted_data['rank'] == desiredRank, colname]\n",
    "\n",
    "    return(output)\n",
    "\n",
    "#using 2 yr return period\n",
    "bank_width = Hydroshortened.groupby('site_no').apply(calculate_bankful, 'chan_width', 2).to_frame()\n",
    "bank_width = bank_width.rename(columns={'chan_width':'bank_width'})\n",
    "Hydroshortened =  pd.merge(Hydroshortened, bank_width, on='site_no')\n",
    "\n",
    "bank_depth = Hydroshortened.groupby('site_no').apply(calculate_bankful, 'chan_depth', 2).to_frame()\n",
    "bank_depth = bank_depth.rename(columns={'chan_depth':'bank_depth'})\n",
    "Hydroshortened =  pd.merge(Hydroshortened, bank_depth, on='site_no')\n",
    "\n",
    "bank_Q = Hydroshortened.groupby('site_no').apply(calculate_bankful, 'chan_discharge', 2).to_frame()\n",
    "bank_Q = bank_Q.rename(columns={'chan_discharge':'bank_Q'})\n",
    "Hydroshortened =  pd.merge(Hydroshortened, bank_Q, on='site_no')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen>Clean the dataset of impossible hydraulic geometry measurements and other impossible values (and get width AMHG) </font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#AHG r2 function\n",
    "def regress3(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.rsquared #only get r2\n",
    "\n",
    "#filter impossible hydraulic geometry\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['b'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['b'] < 1]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['f'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['f'] < 1]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['m'] > 0]\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['m'] < 1]\n",
    "\n",
    "#width AMHG\n",
    "bySite = Hydroshortened.groupby('site_no').mean()\n",
    "logWc_temp = Hydroshortened.groupby('river_name').apply(regress2, 'loga', ['b']).to_frame()\n",
    "logWc_temp = logWc_temp.rename(columns={0: \"logQc_w\"})\n",
    "\n",
    "logQc_w_temp = Hydroshortened.groupby('river_name').apply(regress, 'loga', ['b']).to_frame()*-1\n",
    "logQc_w_temp = logQc_w_temp.rename(columns={0: \"logWc\"})\n",
    "\n",
    "amhg_r2 = Hydroshortened.groupby('river_name').apply(regress3, 'loga', ['b']).to_frame()\n",
    "amhg_r2 = amhg_r2.rename(columns={0:'amhg_r2'})\n",
    "\n",
    "Hydroshortened =  pd.merge(Hydroshortened, logWc_temp, on='river_name')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, logQc_w_temp, on='river_name')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, amhg_r2, on='river_name')\n",
    "\n",
    "#Max grain size entrained per Henderson, 1966 per Strickler I think\n",
    "Hydroshortened['De'] = 11*Hydroshortened['bank_depth']*Hydroshortened['SLOPE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <font color=darkolivegreen>Resulting Dataset</font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('\\033[1m' + \"# measurements:\")\n",
    "display(len(Hydroshortened.index))\n",
    "\n",
    "print('\\033[1m' + \"# cross-sections:\")\n",
    "display(Hydroshortened.groupby('site_no').ngroups)\n",
    "\n",
    "print('\\033[1m' + \"# rivers:\")\n",
    "display(Hydroshortened.groupby('river_name').ngroups)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#convert lat/long to web mercator function\n",
    "def merc(Coords):\n",
    "    Coordinates = literal_eval(Coords)\n",
    "    lat = Coordinates[0]\n",
    "    lon = Coordinates[1]\n",
    "    \n",
    "    r_major = 6378137.000\n",
    "    x = r_major * math.radians(lon)\n",
    "    scale = x/lon\n",
    "    y = 180.0/math.pi * math.log(math.tan(math.pi/4.0 + \n",
    "        lat * (math.pi/180.0)/2.0)) * scale\n",
    "    return (x, y)\n",
    "\n",
    "#convert Hydroshortened lat/long to mercator\n",
    "Hydroshortened['latlong'] = '(' + Hydroshortened[\"LatSite\"].map(str) + ', ' + Hydroshortened[\"LonSite\"].map(str) + ')'\n",
    "\n",
    "Hydroshortened['long_merc'] = Hydroshortened['latlong'].apply(lambda x: merc(x)[0])\n",
    "Hydroshortened['lat_merc'] = Hydroshortened['latlong'].apply(lambda x: merc(x)[1])\n",
    "\n",
    "grouped = Hydroshortened.groupby('site_no').mean()\n",
    "\n",
    "#plot basemap\n",
    "p = figure(x_range=(-14026255, -7347086), y_range=(2999080, 7170156),\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\", title=\"Field-Measurement Locations\", plot_width=900)\n",
    "p.add_tile(CARTODBPOSITRON)\n",
    "\n",
    "p.circle(x = grouped['long_merc'],\n",
    "         y = grouped['lat_merc'],\n",
    "        size=3,\n",
    "        fill_color='darkgreen')\n",
    "\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen>Calculate Global Priors</font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Hydroshortened['delta'] = 1 + (Hydroshortened['r']*(2/3)) + Hydroshortened['r']\n",
    "\n",
    "Hydroshortened['log10A0'] = np.log10(Hydroshortened['A0'])\n",
    "Hydroshortened['log10r'] = np.log10(Hydroshortened['r'])\n",
    "Hydroshortened['log10n'] = np.log10(Hydroshortened['n'])\n",
    "Hydroshortened['log10unitPower'] = np.log10(Hydroshortened['unitPower'])\n",
    "Hydroshortened['log10De'] = np.log10(Hydroshortened['minEntrain'])\n",
    "\n",
    "Hydroshortened['log10Wb'] = np.log10(Hydroshortened['bank_width'])\n",
    "Hydroshortened['log10Db'] = np.log10(Hydroshortened['bank_depth'])\n",
    "Hydroshortened['log10Qb'] = np.log10(Hydroshortened['bank_Q'])\n",
    "Hydroshortened['log10De'] = np.log10(Hydroshortened['De'])\n",
    "Hydroshortened['log10Wc'] = np.log10(np.exp(Hydroshortened['logWc']))\n",
    "Hydroshortened['log10Q'] = np.log10(Hydroshortened['chan_discharge'])\n",
    "\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.distplot(Hydroshortened['log10Wb'], ax=axs[0], color='y')\n",
    "sns.distplot(Hydroshortened['log10Db'], ax=axs[1], color='g')\n",
    "sns.distplot(Hydroshortened['log10Qb'], ax=axs[2], color='r')\n",
    "sns.distplot(Hydroshortened['log10r'], ax=axs[3])\n",
    "sns.distplot(Hydroshortened['log10Wc'], ax=axs[5])\n",
    "\n",
    "fig.suptitle(\"Whole Dataset Prior Distributions for Wc^(1/b)Qc^-1\")\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "#save prior PDFs (no river type subsetting)\n",
    "priorWb = Hydroshortened['log10Wb'].describe()\n",
    "priorDb = Hydroshortened['log10Db'].describe()\n",
    "prior_r = Hydroshortened['log10r'].describe()\n",
    "priorDe = Hydroshortened['log10De'].describe()\n",
    "priorQb = Hydroshortened['log10Qb'].describe()\n",
    "priorWc = Hydroshortened['log10Wc'].describe()\n",
    "\n",
    "Hydroshortened['log10a'] = np.log10(np.exp(Hydroshortened['loga']))\n",
    "priorA = Hydroshortened['log10a'].describe()\n",
    "\n",
    "priorWb.to_csv('priorsWb.csv')\n",
    "priorDb.to_csv('priorsDb.csv')\n",
    "prior_r.to_csv('priorsr.csv')\n",
    "priorDe.to_csv('priorsDe.csv')\n",
    "priorQb.to_csv('priorsQb.csv')\n",
    "priorA.to_csv('priorsA.csv')\n",
    "priorWc.to_csv('priorsWc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hydroshortened['logchan_width'] = np.log10(Hydroshortened['chan_width'])\n",
    "\n",
    "stdWdths = Hydroshortened.groupby('site_no')['logchan_width'].std().to_frame()\n",
    "stdWdths = stdWdths.rename(columns={'logchan_width':'stdWdth'})\n",
    "meanWdths = Hydroshortened.groupby('site_no')['logchan_width'].mean().to_frame()\n",
    "meanWdths = meanWdths.rename(columns={'logchan_width':'meanWdths'})\n",
    "\n",
    "Hydroshortened =  pd.merge(Hydroshortened, stdWdths, on='site_no')\n",
    "Hydroshortened =  pd.merge(Hydroshortened, meanWdths, on='site_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting predictive models for variables\n",
    "Hydroshortened['log10SLOPE'] = np.log10(Hydroshortened['SLOPE'])\n",
    "forPriors = Hydroshortened.drop_duplicates('site_no') #make version with only one value per station\n",
    "\n",
    "#Use forPriors b/c there should only be one value per station\n",
    "resultB = sm.OLS(forPriors['b'], sm.add_constant(forPriors['stdWdth'])).fit()\n",
    "resultA0 = sm.OLS(forPriors['log10A0'], sm.add_constant(forPriors[['meanWdths','stdWdth']])).fit()\n",
    "resultWb = sm.OLS(forPriors['log10Wb'], sm.add_constant(forPriors[['meanWdths']])).fit()\n",
    "resultDb = sm.OLS(forPriors['log10Db'], sm.add_constant(forPriors[['meanWdths', 'stdWdth']])).fit()\n",
    "result_r = sm.OLS(forPriors['log10r'], sm.add_constant(forPriors[['meanWdths', 'stdWdth', 'b']])).fit()\n",
    "resultQb = sm.OLS(forPriors['log10Qb'], sm.add_constant(forPriors[['meanWdths']])).fit()\n",
    "result_a = sm.OLS(forPriors['log10a'], sm.add_constant(forPriors[['meanWdths', 'stdWdth']])).fit()\n",
    "resultDe = sm.OLS(forPriors['log10De'], sm.add_constant(forPriors[['log10SLOPE']])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset braided stations\n",
    "braidedSites = forPriors[forPriors['r'] < 1]\n",
    "\n",
    "Hydroshortened = Hydroshortened[Hydroshortened['r']>=1]\n",
    "\n",
    "Rbraided  = braidedSites['log10r'].describe()\n",
    "BBraided = braidedSites['b'].describe()\n",
    "\n",
    "braidedRPriors = Rbraided.to_csv('braidedRPriors.csv')\n",
    "braidedBPriors = BBraided.to_csv('braidedBPriors.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4><font color=darkolivegreen>Classification Space via KMeans: An Unsupervised Approach </font> </h4>\n",
    "<p> K-Means is ran as an example of a wholy unsupervsied classification space.  I use the silhouette method to assess the ideal number of classes.  It is a measure of how close a point is to points in the other clusters in the predictor space, where values closer to 1 indicate the sample is far away from neighboring clusters.</p>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#Silhouette Method\n",
    "n_clusters = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "result = []\n",
    "for i in n_clusters:\n",
    "    kmeans_var_silhouette = Hydroshortened[['chan_width','SLOPE', 'StreamOrde','DistDwnstrm', 'chan_material_index', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'FCODEnorm', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA']]\n",
    "    kmeans_silhouette = KMeans(n_clusters= i, random_state=0).fit(kmeans_var_silhouette)\n",
    "    labels = kmeans_silhouette.labels_\n",
    "    score = metrics.silhouette_score(kmeans_var_silhouette, labels, metric='euclidean')\n",
    "    result.append(score)\n",
    "\n",
    "#plot results\n",
    "line = sns.lineplot(x = n_clusters, y=result)\n",
    "line.set_title(\"Silhouette  Analysis\")\n",
    "line.set(xlabel='# Groups', ylabel='Silhouette Score')\n",
    "line"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "kmeans_var = Hydroshortened[['chan_width','SLOPE', 'StreamOrde','DistDwnstrm', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'FCODEnorm', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA']]\n",
    "kmeans = KMeans(n_clusters=8, random_state=0).fit(kmeans_var)\n",
    "y_pred = kmeans.predict(kmeans_var) #predicted values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen>Classification Space via PCA + 'Fluvial Index' </font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#run PCA\n",
    "features = ['chan_width', 'n', 'SLOPE', 'StreamOrde','DistDwnstrm', 'FCODEnorm', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA']\n",
    "x = Hydroshortened.loc[:, features].values # Separating out the features\n",
    "y = Hydroshortened.loc[:,['site_no']].values # Separating out the target\n",
    "x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "pca = PCA(n_components=5) #ran using 5 PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = pca.components_\n",
    "             , columns = ['chan_width', 'n', 'SLOPE', 'StreamOrde','DistDwnstrm', 'FCODEnorm', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Plot explained variance by each principal component 'PC'\n",
    "pca = PCA().fit(x)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance (%)')\n",
    "plt.title('Explained Variance vs. # Principal Components')\n",
    "\n",
    "principalDf\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1>UPDATE</h1>\n",
    "<p>\n",
    "    5 PCs were ultimately selected for analysis as they explain ~75% of variance in the dataset and are not too many to make developing intuitive understandings of the dataset difficult, particularly with only 12 initial variables before dimensionality reduction.\n",
    "</p>\n",
    "<p>\n",
    "   The top weighted metrics for PC1 are unit power, slope, shear stress, and minimum entrained grain size.  For PC2 they are stream order, distance downstream, and drainage area.  For PC3 it is velocity and froude number,  for PC4 it is tidal influence, and PC5 is channel shape.\n",
    "    <br><br>\n",
    "    <b>The main axes of geomorphic variation across these rivers have thus been termed 'Sediment Transport', 'Longitunidal Location', 'Flow State', 'Tidal Influence', and 'Channel Shape'.</b>\n",
    "</p>\n",
    "<br>\n",
    "<p>\n",
    "    I then use a 'geomorphic index' which is just a sum of the top 5 PC values for each measurement.  This is purposefully not weighted by the relative importance of each PC (i.e. they're all weighted equally).  Then, classes are determined by breaking the measurements along the deciles for the distribution\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#get quantiles for PCs and 'top-weighted' variables to assist in supervised classification\n",
    "tertiles = [0.33, 0.66]\n",
    "quantiles= [0.20, 0.40, 0.60, 0.80]\n",
    "octiles = [0.125, 0.24, 0.365, 0.490, 0.615, 0.740, 0.865]\n",
    "deciles = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "#add PC values to hydroshortened\n",
    "Hydroshortened['PC1'] = principalComponents[:,0]\n",
    "Hydroshortened['PC2'] = principalComponents[:,1]\n",
    "Hydroshortened['PC3'] = principalComponents[:,2]\n",
    "Hydroshortened['PC4'] = principalComponents[:,3]\n",
    "Hydroshortened['PC5'] = principalComponents[:,4]\n",
    "\n",
    "Hydroshortened['geomorphIndex'] = (Hydroshortened['PC1'])+(Hydroshortened['PC2'])+(Hydroshortened['PC3'])+(Hydroshortened['PC4'])+(Hydroshortened['PC5'])\n",
    "geomorphIndex = np.quantile(Hydroshortened['geomorphIndex'], octiles)\n",
    "\n",
    "Hydroshortened['clusterGeomorphIndex'] = np.where(Hydroshortened['geomorphIndex']<geomorphIndex[0], '1', \n",
    "                                               np.where(Hydroshortened['geomorphIndex']<geomorphIndex[1], '2', \n",
    "                                                       np.where(Hydroshortened['geomorphIndex']<geomorphIndex[2], '3', \n",
    "                                                               np.where(Hydroshortened['geomorphIndex']<geomorphIndex[3], '4',\n",
    "                                                                        np.where(Hydroshortened['geomorphIndex']<geomorphIndex[4], '5', \n",
    "                                                                                 np.where(Hydroshortened['geomorphIndex']<geomorphIndex[5], '6', \n",
    "                                                                                          np.where(Hydroshortened['geomorphIndex']<geomorphIndex[6], '7', '8')))))))\n",
    "                                                                                                   #np.where(Hydroshortened['geomorphIndex']<geomorphIndex[7], '8',\n",
    "                                                                                                   #        np.where(Hydroshortened['geomorphIndex']<geomorphIndex[8], '9', '10')))))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen>KMeans classes vs. Priors</font></h4>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hydroshortened['cluster'] = kmeans.labels_\n",
    "Hydroshortened['logQ'] = np.log10(Hydroshortened['chan_discharge'])\n",
    "\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.boxplot(x=\"cluster\", y='log10A0', data=Hydroshortened, palette='deep', ax=axs[0])\n",
    "sns.boxplot(x=\"cluster\", y='log10n', data=Hydroshortened, palette='deep', ax=axs[1])\n",
    "sns.boxplot(x=\"cluster\", y='b', data=Hydroshortened, palette='deep', ax=axs[2])\n",
    "sns.boxplot(x=\"cluster\", y='logQc_w', data=Hydroshortened, palette='deep', ax=axs[3])\n",
    "sns.boxplot(x=\"cluster\", y='log10SLOPE', data=Hydroshortened, palette='deep', ax=axs[4])\n",
    "sns.boxplot(x=\"cluster\", y='logchan_width', data=Hydroshortened, palette='deep', ax=axs[5])\n",
    "\n",
    "fig.suptitle(\"KMeans Class-Specific Prior Distributions\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[4].set(ylim=(-1, 2))\n",
    "axs[3].set(ylim=(-1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h4> <font color=darkolivegreen> PCA-based Classes vs. Priors</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "forPriors = Hydroshortened.drop_duplicates('site_no') #make version with only one value per station\n",
    "\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logchan_width', data=Hydroshortened, palette='deep', ax=axs[0], order=['1', '2', '3', '4', '5', '6', '7', '8'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10n', data=Hydroshortened, palette='deep', ax=axs[1], order=['1', '2', '3', '4', '5', '6', '7', '8'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='b', data=forPriors, palette='deep', ax=axs[2], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10Wb', data=forPriors, palette='deep', ax=axs[3], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10Db', data=forPriors, palette='deep', ax=axs[4], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10r', data=forPriors, palette='deep', ax=axs[5], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "fig.suptitle(\"Geomorphic Index Class-Specific Prior Distributions\")\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[5].set(ylim=(-0.5, 1))\n",
    "#axs[1].set(ylim=(-2.5, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> <font color=darkolivegreen>Save subsetted parametric distributions by river type</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maps class to river based on 'clostest' median width of class and reach-averaged river width\n",
    "logWidth = Hydroshortened.groupby('clusterGeomorphIndex')['logchan_width'].describe()\n",
    "logWidth.to_csv('logWidthsbyClass.csv')\n",
    "\n",
    "logQClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10Q'].describe()\n",
    "logQClass.to_csv('logQsbyClass.csv')\n",
    "\n",
    "#save prior PDFs (no river type subsetting)\n",
    "priorWbClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10Wb'].describe()\n",
    "priorDbClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10Db'].describe()\n",
    "prior_rClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10r'].describe()\n",
    "priorA0Class = Hydroshortened.groupby('clusterGeomorphIndex')['log10A0'].describe()\n",
    "priorNClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10n'].describe()\n",
    "priorBClass = Hydroshortened.groupby('clusterGeomorphIndex')['b'].describe()\n",
    "\n",
    "Hydroshortened['log10a'] = np.log10(np.exp(Hydroshortened['loga']))\n",
    "priorAClass = Hydroshortened.groupby('clusterGeomorphIndex')['log10a'].describe()\n",
    "\n",
    "#priorWbClass.to_csv('priorsWbClass.csv')\n",
    "#priorDbClass.to_csv('priorsDbClass.csv')\n",
    "#prior_rClass.to_csv('priorsRClass.csv')\n",
    "#priorAClass.to_csv('priorsAClass.csv')\n",
    "#priorA0Class.to_csv('priorsA0Class.csv')\n",
    "priorNClass.to_csv('priorsNClass.csv')\n",
    "#priorBClass.to_csv('priorsBClass.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=darkcyan> Analysis Using MERIT Hydro- NOT RUNNING </font></h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MERITshortened['chan_depth'] = MERITshortened['chan_area']/MERITshortened['chan_width']\n",
    "MERITshortened['chan_material'] = np.where(MERITshortened['chan_material'] == 'silt', 'SILT', MERITshortened['chan_material'])\n",
    "\n",
    "#some cleaning (NA values and hydraulics below 0)\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_width'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_depth'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_discharge'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['measured_rating_diff'] != 'Poor']\n",
    "MERITshortened = MERITshortened[MERITshortened['measured_rating_diff'] != 'POOR']\n",
    "\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_width'].notnull()]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_depth'].notnull()]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_discharge'].notnull()]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_width'].notna()]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_depth'].notna()]\n",
    "MERITshortened = MERITshortened[MERITshortened['chan_discharge'].notna()]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "MERITshortened['Rh'] = MERITshortened['chan_area']/(MERITshortened['chan_depth'] + (2*MERITshortened['chan_width']))\n",
    "MERITshortened['n'] = ((MERITshortened['Rh'])**(2/3)*MERITshortened['slope']**(1/2))/MERITshortened['chan_velocity']\n",
    "MERITshortened['shearStress'] = 9.81*MERITshortened['Rh']*MERITshortened['slope']\n",
    "MERITshortened['Fb'] = MERITshortened['chan_velocity']/((MERITshortened['chan_depth']*9.81)**(1/2))\n",
    "MERITshortened['minEntrain'] = 11*MERITshortened['chan_depth']*MERITshortened['slope']\n",
    "\n",
    "#A0\n",
    "MERITshortened = MERITshortened.join(MERITshortened.groupby('site_no')['chan_area'].agg(['min']), on='site_no')\n",
    "MERITshortened = MERITshortened.rename(columns={\"min\": \"A0\"})\n",
    "\n",
    "#AHG exp function\n",
    "def regress(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params[0] #only get exp\n",
    "\n",
    "#AHG int function\n",
    "def regress2(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.params[1] #only get int\n",
    "\n",
    "#AHG r2 function\n",
    "def regress3(data, yvar, xvars):\n",
    "    Y = np.log(data[yvar])\n",
    "    X = np.log(data[xvars])\n",
    "    X['intercept'] = 1.\n",
    "    result = sm.OLS(Y, X).fit()\n",
    "    return result.rsquared #only get r2\n",
    "\n",
    "\n",
    "groupSize = MERITshortened.groupby('site_no').size().to_frame()\n",
    "MERITshortened = MERITshortened.merge(groupSize, on='site_no')\n",
    "\n",
    "b_temp = MERITshortened.groupby('site_no').apply(regress, 'chan_width', ['chan_discharge']).to_frame()\n",
    "a_temp = MERITshortened.groupby('site_no').apply(regress2, 'chan_width', ['chan_discharge']).to_frame()\n",
    "f_temp = MERITshortened.groupby('site_no').apply(regress, 'chan_depth', ['chan_discharge']).to_frame()\n",
    "c_temp = MERITshortened.groupby('site_no').apply(regress2, 'chan_depth', ['chan_discharge']).to_frame()\n",
    "m_temp = MERITshortened.groupby('site_no').apply(regress, 'chan_velocity', ['chan_discharge']).to_frame()\n",
    "k_temp = MERITshortened.groupby('site_no').apply(regress2, 'chan_velocity', ['chan_discharge']).to_frame()\n",
    "\n",
    "MERITshortened =  pd.merge(MERITshortened, b_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened =  pd.merge(MERITshortened, a_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened = MERITshortened.rename(columns={'0_y': \"b\"})\n",
    "MERITshortened = MERITshortened.rename(columns={'0_x': \"AHGsize\"})\n",
    "MERITshortened = MERITshortened.rename(columns={0: \"loga\"})\n",
    "\n",
    "#Hydroshortened = Hydroshortened[Hydroshortened['AHGsize'] > 20] #need at least 20 at-a-station measurements to build AHG rating curve\n",
    "\n",
    "MERITshortened =  pd.merge(MERITshortened, f_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened =  pd.merge(MERITshortened, m_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened = MERITshortened.rename(columns={'0_y': \"m\"})\n",
    "MERITshortened = MERITshortened.rename(columns={'0_x': \"f\"})\n",
    "\n",
    "MERITshortened =  pd.merge(MERITshortened, c_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened =  pd.merge(MERITshortened, k_temp, right_index=True, left_on='site_no')\n",
    "MERITshortened = MERITshortened.rename(columns={'0_y': \"logc\"})\n",
    "MERITshortened = MERITshortened.rename(columns={'0_x': \"logk\"})\n",
    "\n",
    "MERITshortened['r'] = MERITshortened['f']/MERITshortened['b']\n",
    "MERITshortened['unitPower'] = (998*9.8*MERITshortened['chan_discharge']*MERITshortened['slope'])/MERITshortened['chan_width']\n",
    "MERITshortened['chan_material_index'] = np.where(MERITshortened['chan_material'] == 'BLDR', 1,\n",
    "                                                np.where(MERITshortened['chan_material'] == 'GRVL', 2,\n",
    "                                                        np.where(MERITshortened['chan_material'] == 'SAND', 3,\n",
    "                                                                np.where(MERITshortened['chan_material'] == 'SILT', 4,\n",
    "                                                                        np.where(MERITshortened['chan_material'] == 'UNSP', 5,5)))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#convert needed units to metric\n",
    "MERITshortened['chan_width'] = MERITshortened['chan_width']*0.305\n",
    "MERITshortened['chan_depth'] = MERITshortened['chan_depth']*0.305\n",
    "MERITshortened['chan_velocity'] = MERITshortened['chan_velocity']*0.305\n",
    "MERITshortened['chan_discharge'] = MERITshortened['chan_discharge']*0.028\n",
    "\n",
    "MERITshortened['HRT'] = (MERITshortened['chan_velocity']*0.001)/MERITshortened['lengthkm'] #m/s to km/s\n",
    "\n",
    "#filter impossible hydraulic geometry\n",
    "MERITshortened = MERITshortened[MERITshortened['b'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['b'] < 1]\n",
    "MERITshortened = MERITshortened[MERITshortened['f'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['f'] < 1]\n",
    "MERITshortened = MERITshortened[MERITshortened['m'] > 0]\n",
    "MERITshortened = MERITshortened[MERITshortened['m'] < 1]\n",
    "\n",
    "#width AMHG\n",
    "bySite = MERITshortened.groupby('site_no').mean()\n",
    "logWc_temp = MERITshortened.groupby('river_name').apply(regress2, 'loga', ['b']).to_frame()\n",
    "logQc_w_temp = MERITshortened.groupby('river_name').apply(regress, 'loga', ['b']).to_frame()*-1\n",
    "amhg_r2 = MERITshortened.groupby('river_name').apply(regress3, 'loga', ['b']).to_frame()\n",
    "\n",
    "MERITshortened =  pd.merge(MERITshortened, logWc_temp, right_index=True, left_on='river_name')\n",
    "MERITshortened =  pd.merge(MERITshortened, logQc_w_temp, right_index=True, left_on='river_name')\n",
    "MERITshortened = MERITshortened.rename(columns={'0_y': \"logQc_w\"})\n",
    "MERITshortened = MERITshortened.rename(columns={'0_x': \"logWc\"})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#MERITshortened = MERITshortened[MERITshortened['unitarea']>0]\n",
    "\n",
    "print('\\033[1m' + \"# measurements:\")\n",
    "display(len(MERITshortened.index))\n",
    "\n",
    "print('\\033[1m' + \"# cross-sections:\")\n",
    "display(MERITshortened.groupby('site_no').ngroups)\n",
    "\n",
    "print('\\033[1m' + \"# rivers:\")\n",
    "display(MERITshortened.groupby('river_name').ngroups)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#convert lat/long to web mercator function\n",
    "def merc(Coords):\n",
    "    Coordinates = literal_eval(Coords)\n",
    "    lat = Coordinates[0]\n",
    "    lon = Coordinates[1]\n",
    "    \n",
    "    r_major = 6378137.000\n",
    "    x = r_major * math.radians(lon)\n",
    "    scale = x/lon\n",
    "    y = 180.0/math.pi * math.log(math.tan(math.pi/4.0 + \n",
    "        lat * (math.pi/180.0)/2.0)) * scale\n",
    "    return (x, y)\n",
    "\n",
    "#convert MERITshortened lat/long to mercator\n",
    "MERITshortened['latlong'] = '(' + MERITshortened[\"lat\"].map(str) + ', ' + MERITshortened[\"lon\"].map(str) + ')'\n",
    "\n",
    "MERITshortened['long_merc'] = MERITshortened['latlong'].apply(lambda x: merc(x)[0])\n",
    "MERITshortened['lat_merc'] = MERITshortened['latlong'].apply(lambda x: merc(x)[1])\n",
    "\n",
    "grouped = MERITshortened.groupby('site_no').mean()\n",
    "\n",
    "#plot basemap\n",
    "p = figure(x_range=(-14026255, -7347086), y_range=(2999080, 7170156),\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\", title=\"Field-Measurement Locations\", plot_width=900)\n",
    "p.add_tile(CARTODBPOSITRON)\n",
    "\n",
    "p.circle(x = grouped['long_merc'],\n",
    "         y = grouped['lat_merc'],\n",
    "        size=3,\n",
    "        fill_color='darkgreen')\n",
    "\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "kmeans_var = MERITshortened[['chan_width', 'n', 'slope', 'order_', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'unitarea', 'Fb', 'shearStress', 'minEntrain', 'sinuosity', 'strmDrop_t', 'maxup', 'HRT']]\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(kmeans_var)\n",
    "y_pred = kmeans.predict(kmeans_var) #predicted values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#run PCA\n",
    "features = ['chan_width', 'n', 'slope', 'order_', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'unitarea', 'Fb', 'shearStress', 'minEntrain', 'sinuosity', 'strmDrop_t', 'maxup', 'HRT']\n",
    "x = MERITshortened.loc[:, features].values # Separating out the features\n",
    "y = MERITshortened.loc[:,['site_no']].values # Separating out the target\n",
    "x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "pca = PCA(n_components=5) #ran using 5 PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = pca.components_\n",
    "             , columns = ['chan_width', 'n', 'slope', 'order_', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'unitarea', 'Fb', 'shearStress', 'minEntrain', 'sinuosity', 'strmDrop_t', 'maxup', 'HRT'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Plot explained variance by each principal component 'PC'\n",
    "pca = PCA().fit(x)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance (%)')\n",
    "plt.title('Explained Variance vs. # Principal Components')\n",
    "\n",
    "#Present table of relative weighings of each predictor variable on each resulting PC\n",
    "principalDf\n",
    "#pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#get quantiles for PCs and 'top-weighted' variables to assist in supervised classification\n",
    "tertiles = [0.33, 0.66]\n",
    "quantiles= [0.20, 0.40, 0.60, 0.80]\n",
    "deciles = [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "hexadeciles = [0.0625, 0.1250, 0.1875, 0.25, 0.3125, 0.375, 0.4375, 0.50, 0.5625, 0.625, 0.6875, 0.75, 0.8125, 0.875, 0.9375]\n",
    "\n",
    "#add PC values to hydroshortened\n",
    "MERITshortened['PC1'] = principalComponents[:,0]\n",
    "MERITshortened['PC2'] = principalComponents[:,1]\n",
    "MERITshortened['PC3'] = principalComponents[:,2]\n",
    "MERITshortened['PC4'] = principalComponents[:,3]\n",
    "MERITshortened['PC5'] = principalComponents[:,4]\n",
    "\n",
    "MERITshortened['geomorphIndex'] = (MERITshortened['PC1'])+(MERITshortened['PC2'])+(MERITshortened['PC3'])+(MERITshortened['PC4'])+(MERITshortened['PC5'])\n",
    "geomorphIndex = np.quantile(MERITshortened['geomorphIndex'], deciles)\n",
    "\n",
    "MERITshortened['clusterGeomorphIndex'] = np.where(MERITshortened['geomorphIndex']<geomorphIndex[0], '1', \n",
    "                                               np.where(MERITshortened['geomorphIndex']<geomorphIndex[1], '2', \n",
    "                                                       np.where(MERITshortened['geomorphIndex']<geomorphIndex[2], '3', \n",
    "                                                               np.where(MERITshortened['geomorphIndex']<geomorphIndex[3], '4',\n",
    "                                                                        np.where(MERITshortened['geomorphIndex']<geomorphIndex[4], '5', \n",
    "                                                                                 np.where(MERITshortened['geomorphIndex']<geomorphIndex[5], '6', \n",
    "                                                                                          np.where(MERITshortened['geomorphIndex']<geomorphIndex[6], '7',\n",
    "                                                                                                   np.where(MERITshortened['geomorphIndex']<geomorphIndex[7], '8',\n",
    "                                                                                                           np.where(MERITshortened['geomorphIndex']<geomorphIndex[8], '9', '10')))))))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plot kmeans classes\n",
    "MERITshortened['cluster'] = kmeans.labels_\n",
    "MERITshortened['logQ'] = np.log10(MERITshortened['chan_discharge'])\n",
    "MERITshortened['log10A0'] = np.log10(MERITshortened['A0'])\n",
    "MERITshortened['log10n'] = np.log10(MERITshortened['n'])\n",
    "\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.boxplot(x=\"cluster\", y='log10A0', data=MERITshortened, palette='deep', ax=axs[0])\n",
    "sns.boxplot(x=\"cluster\", y='log10n', data=MERITshortened, palette='deep', ax=axs[1])\n",
    "sns.boxplot(x=\"cluster\", y='b', data=MERITshortened, palette='deep', ax=axs[2])\n",
    "sns.boxplot(x=\"cluster\", y='logQc_w', data=MERITshortened, palette='deep', ax=axs[3])\n",
    "sns.boxplot(x=\"cluster\", y='logWc', data=MERITshortened, palette='deep', ax=axs[4])\n",
    "sns.boxplot(x=\"cluster\", y='logQ', data=MERITshortened, palette='deep', ax=axs[5])\n",
    "\n",
    "fig.suptitle(\"KMeans Class-Specific Prior Distributions\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[4].set(ylim=(-1, 2))\n",
    "axs[3].set(ylim=(-1, 2))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plot index classes\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10A0', data=MERITshortened, palette='deep', ax=axs[0], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='log10n', data=MERITshortened, palette='deep', ax=axs[1], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='b', data=MERITshortened, palette='deep', ax=axs[2], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logQc_w', data=MERITshortened, palette='deep', ax=axs[3], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logWc', data=MERITshortened, palette='deep', ax=axs[4], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logQ', data=MERITshortened, palette='deep', ax=axs[5], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "fig.suptitle(\"Geomorphic Index Class-Specific Prior Distributions\")\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[4].set(ylim=(-0.2, 1.4))\n",
    "axs[3].set(ylim=(0, 1))\n",
    "#axs[1].set(ylim=(-1, 1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#plot AHG parameters per index class\n",
    "fig, axs = plt.subplots(ncols=6, figsize=(12, 8))\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='loga', data=MERITshortened, palette='deep', ax=axs[0], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logc', data=MERITshortened, palette='deep', ax=axs[1], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='logk', data=MERITshortened, palette='deep', ax=axs[2], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='b', data=MERITshortened, palette='deep', ax=axs[3], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='f', data=MERITshortened, palette='deep', ax=axs[4], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "sns.boxplot(x=\"clusterGeomorphIndex\", y='m', data=MERITshortened, palette='deep', ax=axs[5], order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "fig.suptitle(\"Geomorphic Index Class-Specific Prior Distributions\")\n",
    "fig.autofmt_xdate(rotation=90)\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[4].set(ylim=(0, 1))\n",
    "axs[3].set(ylim=(0, 1))\n",
    "axs[5].set(ylim=(0,1))\n",
    "axs[1].set(ylim=(-4, -0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=darkcyan> Compare Classifications Using NHD v2.1 and MERIT Hydro </font></h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#PCA MERIT Hydro\n",
    "features = ['chan_width', 'n', 'slope', 'order_', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'unitarea', 'Fb', 'shearStress', 'minEntrain', 'sinuosity', 'HRT']\n",
    "xMERIT = MERITshortened.loc[:, features].values # Separating out the features\n",
    "yMERIT = MERITshortened.loc[:,['site_no']].values # Separating out the target\n",
    "xMERIT = StandardScaler().fit_transform(xMERIT) # normalizing the features\n",
    "\n",
    "pcaMERIT = PCA(n_components=5) #ran using 5 PCs\n",
    "principalComponentsMERIT = pcaMERIT.fit_transform(xMERIT)\n",
    "principalDfMERIT = pd.DataFrame(data = pcaMERIT.components_\n",
    "             , columns = ['chan_width', 'n', 'slope', 'order_', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'unitarea', 'Fb', 'shearStress', 'minEntrain', 'sinuosity', 'HRT'])\n",
    "\n",
    "#PCA NHD 2.1\n",
    "features = ['chan_width', 'n', 'SLOPE', 'StreamOrde', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA', 'sinuosity']\n",
    "x = Hydroshortened.loc[:, features].values # Separating out the features\n",
    "y = Hydroshortened.loc[:,['site_no']].values # Separating out the target\n",
    "x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "pca = PCA(n_components=5) #ran using 5 PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = pca.components_\n",
    "             , columns = ['chan_width', 'n', 'SLOPE', 'StreamOrde', 'chan_depth', 'chan_velocity', 'unitPower', 'r', 'DASqKm', 'Fb', 'shearStress', 'minEntrain', 'TOTMA', 'sinuosity'])\n",
    "\n",
    "principalDfMERIT\n",
    "\n",
    "#1: power (0.47), shear (0.48), minentrain (0.53), slope (0.37)\n",
    "#2: velocity (0.62), Fb (0.60), HRT (0.51)\n",
    "#3: width (0.45), slope (-0.41), order (0.53), depth (0.44)\n",
    "#4: sinuosity (0.59), catchment area (0.49)\n",
    "#5: r (-0.62), width (-0.50), n (-0.37)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "principalDf\n",
    "#1: power (0.46), shear (0.50), minEntrain (0.50), slope (0.44)\n",
    "#2: velocity (0.53, Fb (0.50)\n",
    "#3: order (-0.42), velocity (0.47), Fb (0.50), catchment area (-0.42)\n",
    "#4: HRT (-0.74), sinuosity (-0.60)\n",
    "#5: r (-0.87)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Plot explained variance MERIT\n",
    "pcaMERIT = PCA().fit(xMERIT)\n",
    "\n",
    "#Plot explained variance by NHD v2.1\n",
    "pca = PCA().fit(x)\n",
    "\n",
    "MERITplot = plt.plot(np.cumsum(pcaMERIT.explained_variance_ratio_))\n",
    "NHDplot = plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance (%)')\n",
    "plt.title('Explained Variance vs. # Principal Components (MERIT orange, NHD blue)')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Comparing measurements per order by hydrography\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(12, 8))\n",
    "\n",
    "sns.countplot(x='order_', data=MERITshortened, ax=axs[0], palette='dark')\n",
    "sns.countplot(x='StreamOrde', data=Hydroshortened, ax=axs[1], palette='dark')\n",
    "axs[1].text(1,100000,'NHD 2.1', size=20)\n",
    "axs[0].text(0,100000,'MERIT Hydro', size=20)\n",
    "\n",
    "fig.suptitle(\"Field Measurements per Stream Order\")\n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "axs[0].set(ylim=(0, 120000))\n",
    "axs[1].set(ylim=(0, 120000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>R classification space for CT HRT model </h1>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "output = Hydroshortened.groupby('clusterGeomorphIndex')['r'].median().to_frame()\n",
    "\n",
    "#save r to each class and output to file\n",
    "channels = pd.read_csv('C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\Routing\\working\\channels_fin.txt', sep=\"\\t\", header=None)\n",
    "channels = channels.rename(columns={14: 'NHDPlusID'})\n",
    "channels = channels.rename(columns={12: 'width'})\n",
    "channels = channels.rename(columns={11: 'n'})\n",
    "channels = channels.rename(columns={4: 'catchArea'})\n",
    "\n",
    "nhd_CT = pd.read_csv('C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\working_drive_4_watersheds\\CT\\NHD_HR_merged.txt', sep=\"\\t\")\n",
    "nhd_CT = pd.merge(nhd_CT, channels, on='NHDPlusID')\n",
    "nhd_CT['FCODEnorm'] = np.where(nhd_CT['FCode'] == 33400, 1, #connectors or canals\n",
    "                                                np.where(nhd_CT['FCode'] == 33600, 1, #connectors or canal\n",
    "                                                        np.where(nhd_CT['FCode'] == 46003, 2, #intermittent river\n",
    "                                                                np.where(nhd_CT['FCode'] == 46006, 3, 4))))#perienial river, lake/wetland/reservoir = 4\n",
    "\n",
    "nhd_CT['unitPower'] = (998*9.8*nhd_CT['QEMA']*nhd_CT['Slope'])/nhd_CT['width']\n",
    "\n",
    "\n",
    "\n",
    "#run PCA\n",
    "features = ['n', 'Slope', 'StreamOrde', 'FCODEnorm', 'unitPower', 'catchArea']\n",
    "x = nhd_CT.loc[:, features].values # Separating out the features\n",
    "#y = nhd_CT.loc[:,['site_no']].values # Separating out the target\n",
    "x = StandardScaler().fit_transform(x) # normalizing the features\n",
    "\n",
    "pca = PCA(n_components=5) #ran using 5 PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = pca.components_\n",
    "             , columns = ['n', 'Slope', 'StreamOrde', 'FCODEnorm', 'unitPower', 'catchArea'])\n",
    "\n",
    "deciles = [0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "\n",
    "#add PC values to hydroshortened\n",
    "nhd_CT['PC1'] = principalComponents[:,0]\n",
    "nhd_CT['PC2'] = principalComponents[:,1]\n",
    "nhd_CT['PC3'] = principalComponents[:,2]\n",
    "nhd_CT['PC4'] = principalComponents[:,3]\n",
    "nhd_CT['PC5'] = principalComponents[:,4]\n",
    "\n",
    "nhd_CT['geomorphIndex'] = (nhd_CT['PC1'])+(nhd_CT['PC2'])+(nhd_CT['PC3'])+(nhd_CT['PC4'])\n",
    "geomorphIndex = np.quantile(nhd_CT['geomorphIndex'], deciles)\n",
    "\n",
    "nhd_CT['clusterGeomorphIndex'] = np.where(nhd_CT['geomorphIndex']<geomorphIndex[0], '1', \n",
    "                                               np.where(nhd_CT['geomorphIndex']<geomorphIndex[1], '2', \n",
    "                                                       np.where(nhd_CT['geomorphIndex']<geomorphIndex[2], '3', \n",
    "                                                               np.where(nhd_CT['geomorphIndex']<geomorphIndex[3], '4',\n",
    "                                                                        np.where(nhd_CT['geomorphIndex']<geomorphIndex[4], '5', \n",
    "                                                                                 np.where(nhd_CT['geomorphIndex']<geomorphIndex[5], '6', \n",
    "                                                                                          np.where(nhd_CT['geomorphIndex']<geomorphIndex[6], '7',\n",
    "                                                                                                   np.where(nhd_CT['geomorphIndex']<geomorphIndex[7], '8',\n",
    "                                                                                                           np.where(nhd_CT['geomorphIndex']<geomorphIndex[8], '9', '10')))))))))\n",
    "\n",
    "sns.barplot(x='clusterGeomorphIndex', y='width', data=nhd_CT, palette='dark', order=['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'])\n",
    "\n",
    "nhd_CT = pd.merge(nhd_CT, output, on='clusterGeomorphIndex')\n",
    "\n",
    "nhd_CT = nhd_CT[['NHDPlusID','clusterGeomorphIndex', 'r']]\n",
    "\n",
    "nhd_CT.to_csv(r'C:\\Users\\cbrinkerhoff\\Box Sync\\Ongoing Projects\\Watershed_Rules_of_Life\\working_drive_4_watersheds\\CT\\NHD_HR_CT_w_r.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
